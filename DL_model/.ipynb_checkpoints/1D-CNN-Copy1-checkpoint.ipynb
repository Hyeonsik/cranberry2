{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D-CNN model\n",
    "<br>\n",
    "- skeletal code: https://github.com/vitaldb/maic2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:53:34.428950Z",
     "start_time": "2020-11-16T13:53:27.670277Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "MINUTES_AHEAD = 5\n",
    "SRATE = 100 # 100Hz\n",
    "LEN_INPUT = 10 # input 길이는 10초\n",
    "\n",
    "# 2초 moving average\n",
    "def moving_average(a, n=200):\n",
    "    ret = np.nancumsum(a, dtype=np.float32)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "# training set 로딩\n",
    "x_total_ppg, x_total_ecg = [], []\n",
    "x_train = []  # ppg, ecg waveform (10s each)\n",
    "y_total = []\n",
    "y_train = []  # NRS 0.0 ~ 10.0\n",
    "\n",
    "\n",
    "if os.path.exists('x_total_ppg.npz'):\n",
    "    print('loading train...', flush=True, end='')\n",
    "    x_total_ppg = np.load('x_total_ppg.npz', allow_pickle=True)['arr_0']\n",
    "    x_total_ecg = np.load('x_total_ecg.npz', allow_pickle=True)['arr_0']\n",
    "    y_total = np.load('y_total.npz')['arr_0']\n",
    "    print('done', flush=True)\n",
    "    \n",
    "else:\n",
    "    # augmentated data의 합격 여부 loading\n",
    "    df_preprocess = pickle.load(open('../Preprocessing/cache/df_preprocess_total', 'rb'))\n",
    "    \n",
    "    \n",
    "    vital_path = '../Preprocessing/NRS_vital_pickle_unzip/NRS_vital_pickle'\n",
    "    row_cnt = 0\n",
    "    for _, row in df_preprocess.iterrows():\n",
    "        row_cnt +=1\n",
    "        print('loading data',row_cnt,\"...\", end='')\n",
    "        # vital data loading\n",
    "        df_vital = pickle.load(open(vital_path+'/'+row['file_path'], 'rb')).reset_index()\n",
    "        \n",
    "        # 한 NRS에 대해 23개의 input 확인\n",
    "        for i in range(23):\n",
    "            # input이 전처리 통과한 경우\n",
    "            if row[str(i+1)][0]:\n",
    "                start_idx = i*5*SRATE # 500i\n",
    "                end_idx = (i*5 + LEN_INPUT)*SRATE # 500i + 1000\n",
    "                df_vital_input = df_vital.loc[start_idx:end_idx-1]\n",
    "                #df_vital_input = df_vital_input.fillna(method='ffill').fillna(method='bfill').values\n",
    "                \n",
    "                pleth_inp, ecg_inp = [np.nan for j in range(LEN_INPUT*SRATE)], [np.nan for j in range(LEN_INPUT*SRATE)]\n",
    "                # input의 정규화\n",
    "                pleth_inp[0:df_vital_input['Pleth'].size] = df_vital_input['Pleth'].tolist()\n",
    "                pleth_inp = pleth_inp - np.nanmean(pleth_inp)\n",
    "                \n",
    "                ecg_inp[0:df_vital_input['ECG'].size] = (df_vital_input['ECG'].tolist())\n",
    "                #ecg_inp = (ecg_inp-ecg_inp.min()) / (ecg_inp.max()-ecg_inp.min())\n",
    "                ecg_inp = (ecg_inp - np.nanmean(ecg_inp)) / np.nanstd(ecg_inp)\n",
    "                \n",
    "                x_total_ppg.append(pleth_inp)\n",
    "                x_total_ecg.append(ecg_inp)\n",
    "                y_total.append(int(row['file_path'][0]))\n",
    "\n",
    "        print('completed')\n",
    "    \n",
    "    x_total_ppg = np.array(x_total_ppg, np.float32)        \n",
    "    x_total_ecg = np.array(x_total_ecg, np.float32)\n",
    "    y_total = np.array(y_total, int)\n",
    "    \n",
    "    print('saving...', end='', flush=True)\n",
    "    np.savez_compressed('x_total_ppg.npz', x_total_ppg)\n",
    "    np.savez_compressed('x_total_ecg.npz', x_total_ecg)\n",
    "    np.savez_compressed('y_total.npz', y_total)\n",
    "    print('done', flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:53:37.816890Z",
     "start_time": "2020-11-16T13:53:36.972453Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of x_total: 153250\n",
      "size of y_total: 153250\n"
     ]
    }
   ],
   "source": [
    "# ECG와 PPG input 합치기\n",
    "x_total = []\n",
    "for i in range(len(x_total_ppg)):\n",
    "    x_total.append(x_total_ppg[i]+x_total_ecg[i])\n",
    "\n",
    "# np.array로 변환  \n",
    "x_total = np.array(x_total, np.float32)\n",
    "\n",
    "#NRS score가 4 이하면 0, 4 이상이면 1 (severe pain)\n",
    "#y_total_bin = np.where(y_total < 4, 0, 1)\n",
    "\n",
    "# 총 dataset의 크기\n",
    "print('size of x_total:', len(x_total))\n",
    "print('size of y_total:', len(y_total))\n",
    "\n",
    "# 저장하기\n",
    "#np.savez_compressed('x_total.npz', x_total)\n",
    "#np.savez_compressed('y_total.npz', y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T13:17:32.517548Z",
     "start_time": "2020-11-15T13:17:32.410780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1000: 153250})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = []\n",
    "for x_ele in x_total:\n",
    "    len_list.append(len(x_ele))\n",
    "    \n",
    "from collections import Counter\n",
    "len_hist = Counter(len_list)\n",
    "len_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:53:50.219455Z",
     "start_time": "2020-11-17T05:53:45.479389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test...done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test set 로딩\n",
    "if os.path.exists('x_test.npz'):\n",
    "    print('loading test...', flush=True, end='')\n",
    "    x_test = np.load('x_test.npz', allow_pickle=True)['arr_0']\n",
    "    y_test = np.load('y_test.npz')['arr_0']\n",
    "    \n",
    "    x_train = np.load('x_train.npz', allow_pickle=True)['arr_0']\n",
    "    y_train = np.load('y_train.npz')['arr_0']\n",
    "    print('done', flush=True)\n",
    "else:\n",
    "    #training set과 test set으로 나누기\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size = 0.1, shuffle=True)\n",
    "    print('saving...', flush=True, end='')\n",
    "    np.savez_compressed('x_test.npz', x_test)\n",
    "    np.savez_compressed('y_test.npz', y_test)\n",
    "\n",
    "    np.savez_compressed('x_train.npz', x_train)\n",
    "    np.savez_compressed('y_train.npz', y_train)\n",
    "    print('done', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D-CNN model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:53:51.470273Z",
     "start_time": "2020-11-17T05:53:51.462916Z"
    }
   },
   "outputs": [],
   "source": [
    "# binary classification\n",
    "y_train = np.where(y_train < 6, 0, 1)\n",
    "y_test = np.where(y_test < 6, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:53:55.652872Z",
     "start_time": "2020-11-17T05:53:53.319041Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 137925 (106732 events 77.4%), test 15325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# nan 을 이전 값으로 채움\n",
    "x_train = pd.DataFrame(x_train).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "x_test = pd.DataFrame(x_test).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "\n",
    "# CNN에 입력으로 넣기 위해 차원을 추가\n",
    "x_train = x_train[..., None]\n",
    "x_test = x_test[..., None]\n",
    "\n",
    "print('train {} ({} events {:.1f}%), test {}'.format(len(y_train), sum(y_train), 100*np.mean(y_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T05:53:58.883Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512-256-128-64\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPool1D, BatchNormalization, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, f1_score, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "num_nodes = [512, 256, 128, 64]\n",
    "\n",
    "testname = '-'.join([str(num_node) for num_node in num_nodes])\n",
    "print(testname)\n",
    "\n",
    "# 출력 폴더를 생성\n",
    "odir = \"output\"\n",
    "save_path = \"output/\" +\"1D_CNN_\" +\"model_copy_5\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "weight_path = save_path + \"/weights.hdf5\"\n",
    "\n",
    "#GPU * 2\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "with strategy.scope():\n",
    "    # build a model\n",
    "    model = Sequential()\n",
    "    for num_node in num_nodes:\n",
    "        model.add(Conv1D(filters=num_node, kernel_size=15, padding='valid', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "    hist = model.fit(x_train, y_train, validation_split=0.1, epochs=100, batch_size=BATCH_SIZE, class_weight={0:1, 1:1}, \n",
    "                            callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weight_path, verbose=1, save_best_only=True)])\n",
    "                                        #EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')])\n",
    "\n",
    "\n",
    "\n",
    "# 모델을 저장   \n",
    "open(save_path + \"/model.json\", \"wt\").write(model.to_json())\n",
    "model.load_weights(weight_path)\n",
    "\n",
    "# 모델의 history 저장\n",
    "for key in hist.history.keys():\n",
    "    if 'auc' in key and not 'val' in key:\n",
    "        auc = key\n",
    "\n",
    "pickle.dump((hist.history['loss'], hist.history['val_loss'], hist.history['accuracy'], hist.history['val_accuracy'], hist.history[auc], hist.history['val_'+auc]), open(save_path+'/history', 'wb'))\n",
    "# 전체 test 샘플을 한번에 예측\n",
    "y_pred = model.predict(x_test).flatten()\n",
    "\n",
    "# 결과를 저장\n",
    "np.savetxt(save_path+'/pred_y.txt', y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:35:26.729368Z",
     "start_time": "2020-11-17T05:35:26.721952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15325"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:21:13.283824Z",
     "start_time": "2020-11-17T05:21:13.253787Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e94890dad1be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'auc'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'val'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 모델의 history 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "for key in hist.history.keys():\n",
    "    if 'auc' in key and not 'val' in key:\n",
    "        auc = key\n",
    "        \n",
    "# 모델의 history 저장\n",
    "pickle.dump((hist.history['loss'], hist.history['val_loss'], hist.history['accuracy'], hist.history['val_accuracy'], hist.history[auc], hist.history['val_'+auc]), open(save_path+'/history', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T05:19:21.933984Z",
     "start_time": "2020-11-17T05:19:21.608045Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ff956775f6a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0macc_ax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwinx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "#x-axis는 공유하지만 y-axis는 공유x\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T01:22:59.084072Z",
     "start_time": "2020-11-17T01:22:59.021319Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2784583316924712222,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 3589912772080974495\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11188411850657132184\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:1\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 4478664411352884002\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:2\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14019618649442638897\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:3\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14129365938803667788\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 16449536\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 10004079076078008672\n",
       " physical_device_desc: \"device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\",\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 32077774848\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 9261084103765312895\n",
       " physical_device_desc: \"device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0\",\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 32077774848\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 865473553542679999\n",
       " physical_device_desc: \"device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0\",\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 32077774848\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 7669193428324270745\n",
       " physical_device_desc: \"device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU check\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T02:37:22.672702Z",
     "start_time": "2020-11-17T02:37:22.662662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy: 0.7702446982055465\n",
      "0.9904078303425775\n"
     ]
    }
   ],
   "source": [
    "model_y = np.where(y_pred<0.5,0,1)\n",
    "print('test set accuracy:', np.mean(model_y==y_test))\n",
    "print(np.mean(model_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 255.64100000000002,
   "position": {
    "height": "277.641px",
    "left": "1518.75px",
    "right": "20px",
    "top": "115px",
    "width": "441.5px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
